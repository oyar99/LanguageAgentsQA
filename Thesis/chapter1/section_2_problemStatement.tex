\section{Problem Statement}
\label{sec:problemStatement}

Natural language long-input tasks, such as long-document question answering, remain challenging for LLMs despite advancements in extending context windows. Issues such as \textit{lost in the middle} effect and the prohibitively high computational cost of training long-context models make these approaches inefficient and expensive solutions for handling long-range information \cite{liu2023lostmiddlelanguagemodels}\cite{kitaev2020reformerefficienttransformer}. To address these challenges, various agent-based architectures have been proposed in the context of cognitive language agents \cite{sumers2024cognitive}\cite{packer2024memgptllmsoperatingsystems}\cite{li2024graphreaderbuildinggraphbasedagent}\cite{anokhin2024arigraphlearningknowledgegraph}\cite{zhao-etal-2024-longagent}. However, how these agents can be effectively utilized to maximize their planning and reflection capabilities in Question Answering (QA) and Multi-Hop Question Answering (MHQA) tasks, remains largely unexplored.
