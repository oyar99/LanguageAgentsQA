\section{Problem Statement}
\label{sec:problemStatement}

Natural language tasks that require reasoning over long-range information, such as MHQA, remain challenging for LLMs despite recent progress in extending context windows. Limitations such as \textit{lost in the middle} effect and the prohibitively high computational cost of training and operating long-context models make these approaches inefficient and expensive \cite{liu2023lostmiddlelanguagemodels,kitaev2020reformerefficienttransformer}. RAG has become a widely adopted alternative, yet MHQA tasks continue to be challenging due to the multi-step reasoning required for these tasks.

\noindent Recently, cognitive language agent architectures have been proposed to enable decision-making and reasoning capabilities \cite{sumers2024cognitive,packer2024memgptllmsoperatingsystems,li2024graphreaderbuildinggraphbasedagent,anokhin2024arigraphlearningknowledgegraph,zhao-etal-2024-longagent}. However, how these agents can be effectively utilized to maximize their planning and reasoning capabilities in QA and MHQA tasks, remains largely unexplored.
