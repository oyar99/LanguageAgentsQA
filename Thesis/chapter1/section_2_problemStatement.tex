\section{Problem Statement}
\label{sec:problemStatement}

Natural language tasks that require reasoning over long-range information, such as MHQA, remain challenging for LLMs despite recent progress in extending context windows. Limitations such as \textit{lost in the middle} effect and the prohibitively high computational cost of training and operating long-context models make these approaches inefficient and expensive \cite{liu2023lostmiddlelanguagemodels}\cite{kitaev2020reformerefficienttransformer}. RAG has become a widely adopted alternative, yet MHQA tasks continue to be challenging due to the multi-step reasoning required for these tasks.

\noindent Recently, cognitive language-agent architectures have been proposed to enable decision-making and reasoning capabilities \cite{sumers2024cognitive}\cite{packer2024memgptllmsoperatingsystems}\cite{li2024graphreaderbuildinggraphbasedagent}\cite{anokhin2024arigraphlearningknowledgegraph}\cite{zhao-etal-2024-longagent}. However, how these agents can be effectively utilized to maximize their planning and reasoning capabilities in QA and MHQA tasks, remains largely unexplored.
