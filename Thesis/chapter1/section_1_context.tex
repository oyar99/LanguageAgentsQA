\section{Context}
\label{sec:context}

Large Language Models (LLMs) have consistently demonstrated strong performance in various natural language tasks, enabling applications such as conversational interfaces and question answering \cite{minaee2024largelanguagemodelssurvey}. Recent advancements in hardware and model architectures have produced models capable of handling large context windows, including GPT-3.5 Turbo with $16K$ tokens, GPT-4 with up to $32K$ tokens, and Gemini 1.5 Pro with a $2M$-token context window
\cite{liu2023lostmiddlelanguagemodels}\cite{openai2024gpt4technicalreport}\cite{geminiteam2024gemini15unlockingmultimodal}. Despite these efforts, certain problems, such as long-document question answering, remain challenging. Studies have shown that LLM performance degrades when relevant information appears in the middle of the context window rather than at the beginning or end, a phenomenon commonly referred to as \textit{lost in the middle} \cite{liu2023lostmiddlelanguagemodels}. Additionally, simply increasing the context length in transformer-based architectures incurs prohibitively high computational costs \cite{kitaev2020reformerefficienttransformer}.

\noindent To address these limitations, researchers have explored alternative strategies that enable LLMs to retrieve and reason over external information more efficiently. Retrieval Augmented Generation (RAG), a widely adopted approach, integrates new knowledge into LLMs by retrieving relevant content from an external source \cite{lewis2021retrievalaugmentedgenerationknowledgeintensivenlp}. However, RAG alone often struggles to synthesize information from multiple sources and to reason effectively about retrieved content, especially in complex multi-step natural language tasks such as Multi-Hop Question Answering (MHQA) \cite{NEURIPS2024_6ddc001d}\cite{liang2024kagboostingllmsprofessional}.

\noindent Recent work has proposed a more structured framework, \textit{Cognitive Language Agents}, which integrates principles from cognitive science to design intelligent agents that consist of three key components: memory, action, and decision-making. Memory is further categorized into four types: \textit{working memory}, which stores perceptual inputs and active knowledge; \textit{episodic memory}, which retains past experiences; \textit{semantic memory}, which contains factual knowledge about the world; and \textit{procedural memory}, which encodes the rules and functions that govern the agent's interaction with its environment. The agent's internal actions dictate how it engages with these memory components, retrieving, updating, and organizing knowledge to support more coherent reasoning and learning over time \cite{sumers2024cognitive}. Many LLM-based systems designed to enhance long-range information retention and reasoning capabilities can be analyzed through this framework, including the following examples.

\noindent Memory GPT (MemGPT) is a language agent designed to manage large volumes of information more effectively. It incorporates multiple storage tiers, enabling it to handle more input despite its limited context window. The agent maintains procedural memory to encode the rules for reading from and writing to these storage tiers. During reasoning, MemGPT retrieves past knowledge using dense retrieval, drawing from either an episodic or semantic database. The retrieved content is then loaded into working memory to support decision-making for the current task \cite{packer2024memgptllmsoperatingsystems}.

\noindent GraphReader is a language agent specifically designed for handling long-input tasks using structured data. In particular, it utilizes a graph as its long-term memory. This graph is constructed offline by prompting an LLM to extract entities and their related facts, with each vertex representing an entity and its associated information. Once the graph is built, the system retrieves the most relevant nodes using dense retrieval to serve as entry points for exploration. The agent then navigates the graph using a set of predefined functions, such as searching neighboring nodes. The agent follows a rationale-driven plan to aid in decision-making and autonomously determines when it has gathered sufficient information to generate a response \cite{li2024graphreaderbuildinggraphbasedagent}.

\noindent Further advances have introduced other structured approaches that explicitly differentiate between semantic and episodic memory. For example, AriGraph is an agent whose memory module consists of two types of vertices, semantic vertices, which represent entities, and are connected by semantic edges representing relationships; and episodic vertices, corresponding to temporal events and are linked to all semantic vertices observed at a particular time \cite{anokhin2024arigraphlearningknowledgegraph}. While this agent was originally designed for text-based interaction games, its competitive performance on question answering benchmarks suggests that agent-based architectures could be leveraged to implement effective systems for these types of tasks.

\noindent In this work, we systematically evaluate multiple agent-based architectures, inspired by the \textit{Cognitive Language Agent} framework, for solving challenging natural language tasks, specifically Question Answering (QA) and MHQA. The agents take as input a set of questions $Q$, reason through them, and iteratively plan and perform actions until they have gathered sufficient information to produce a confident response. In doing so, they leverage reflection and decision-making capabilities to enhance overall performance.




