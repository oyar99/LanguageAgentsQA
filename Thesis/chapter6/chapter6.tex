\cleardoublepage
\chapter{Conclusion and future work}
\label{ch:conclusion}
\label{ch:chapter6}

We conducted a systematic evaluation of multiple language agent architectures and demonstrated how these architectures can be used for QA systems, particularly for MHQA tasks. Our results show that agents such as the DAG Agent and the Auto DAG Agent leverage both their decision-making and reasoning capabilities to address complex questions, achieving significantly higher recall across all MHQA benchmarks. Additionally, we show that these agents achieve competitive QA performance compared with strong SOTA systems such as HippoRAG. Our results also suggest that language agent architectures remain relatively robust to the choice of the retriever, as the QA Agent performs similarly when using ColBERTv2 or HippoRAG.

\noindent We further demonstrate, using the Long-lived QA Agent, that incorporating cognitive long-term memory components can substantially improve QA performance on certain benchmarks. These memory mechanisms allow agents to retain previously learned information and reuse it effectively when answering new questions.

\noindent However, cognitive language agent architectures also introduce challenges. Their higher token consumption leads to increased inference costs and latency. Among all evaluated systems, the simpler QA Agent based on the ReAct framework offers the best balance between performance and efficiency. Moreover, language agents exhibit limited generalization to other question types and conversational settings. On LoCoMo, traditional RAG systems continue to outperform language agent architectures.

\noindent Small Language Models (SLMs) present opportunities to drastically reduce costs while maintaining, or even improving, task-specific performance. Recently, there has been growing interest in introducing SLMs into agentic systems, as they offer several advantages. Carefully fine-tuned SLMs have demonstrated superior performance compared with generalist LLMs of much larger scale \cite{belcak2025smalllanguagemodelsfuture}. For instance, Microsoft Phi series models show stronger reasoning capabilities across multiple benchmarks than models roughly ten times larger, while also providing substantially faster inference \cite{javaheripi2023neurips, abdin2024phi3technicalreporthighly}. SLMs are also more economical in terms of inference costs, energy consumption, and latency, and can be fine-tuned with methods such as LoRA far more efficiently \cite{belcak2025smalllanguagemodelsfuture,hu2022lora}. 

\noindent These observations support the integration of SLMs into agentic systems, particularly for repetitive or specific tasks, while reserving LLMs for the most demanding operations. In our work, we briefly explored this direction within the DAG Agent and Auto DAG Agent architectures by using GPT-4.1-mini, an instruction-tuned model, for planning and answer synthesis, while relying on a smaller LLM for repetitive tasks such as invoking the search tool. Unfortunately, the models used in both architectures are proprietary, their sizes are not publicly disclosed, and they are generalist models whose full capabilities are unnecessary for our systems.

\noindent Future work could therefore study open-source SLMs with a few billion parameters and fine-tune them with approaches like LoRA for specific tasks, such as search tool invocations, using high-quality synthetic data. Empirically, this approach has proven efficient and can achieve comparable performance to simply training larger models \cite{gunasekar2024textbooks}. Such specialized SLMs could replace GPT-4o-mini for computing $A(q)$ in our language agent designs, potentially reducing inference costs, shortening the prompts required for in-context learning, and improving performance by better aligning the model with task-specific requirements.

\noindent Similarly, while the DAG Agent and the Auto DAG Agent achieve substantially higher retrieval performance, these gains do not translate proportionally into QA improvements. Fine-tuned models designed for reasoning within a QA domain may help reduce this gap by making better use of the additional retrieved information, particularly in scenarios involving conflicting or biased data. 